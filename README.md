# ReadMe: UCI Human Activity Recognition Data Tidying and Analysis
The R script contained in `run_analysis.R` does multiple tasks:
 1. Loads packages used for the data tidying and analysis, installing them from CRAN if they are not available in the host R library
 2. Downloads the UCI archive containing the Human Activity Recognition ('HAR') data to file 'UCI_HAR_Dataset.zip'
 3. Unzips the full archive into target directory 'UCI_Data'
 4. Reads in data needed for tidying and analysis from the archive files for subject, activity, and feature data, and for feature naming 
 5. Identifies and selects feature variables containing `mean()` and `std()`, and transforms variable names to tidier format, and assembles data into single dataframe in tidy format
 6. Performs analysis on tidy data to create a tidy summary
 7. Writes the data and its summary to disk as text files, and loads it into the global environment within R
 
Steps 1 through 3 may be skipped if the user wants to do them manually.  That is done by setting one or more of the three variables in the function call at the bottom of the file to FALSE.  However, even if not set to FALSE, the script does a check on the necessity of each of steps 1 through 3. In step 1, although the packages must be loaded for the function to operate, they are not installed if they can be loaded from the library. In step 2, the archive is not downloaded if a file of the appropriate name is already present in the working directory.  And in step 3, the archive is not unzipped if a set of directories of the appropriate names already exists. 

After the preliminaries of steps 1 through 3 are done, the main data processing is done in steps 4 through 6.  In step 4, the subject, activity, and feature data are read into memory using function `read_table` from `readr` (a package utilized for speed and ease of use). Each of these exists in two parts (test and training data), and these parts are combined before the subject, activity, feature data are merged to form a single tidy dataset.  Before the merging is done, the appropriate features are identified and extracted (just the 66 containing `mean()` and `std()` in their names - a subset of the total 561).  An vector of column numbers is created as part of the feature name identification (this is later used to extract the corresponding feature data). After identification of the desired feature names, the names are tidied for readability.  These names come initially in a combination of formats, including a 'camelcase' segment (each word fragment startig with a capital followed by lower-case letters), a hyphenated segment, parentheses associated with the variable type (such as those in `mean()` and `std()`), and capitalized coordinate directions `X`, `Y`, and `Z` as suffixes.  The names are tidied according to the following protocol: they hyphens are removed, all characters are lower-cased, periods (".") are inserted between all word fragments, and all numbers are removed (note: no features involving `mean()` or `std()` rely on numbers as part of their names - for those variables, the numbers are just used like row names).

In step 5, the data is merged based.  Before merging, the activity names are substituted for activity numbers (1 through 6). The activity names are also tidied, according to a similar protocol to that used for the feature names.  Because all the data rows and columns are (assumed to be!) in the same order across the various text files, the merger itself is not complicated.  `cbind` is used to assemble the column-oriented components, and the column names are set equal to the tidied feature names via the `names()` function.  This results in a dataframe which is 68 columns wide. It has 2 initial columns for the subject and activity factor information, and 66 remaining columns for the selected numeric features.  The number of rows is 10,299.

In step 6, the data is summarized by taking averages of the rows corresponding to each unique subject-activity pair.  With 30 subjects and 6 activities, this results in 180 averages for each of the 66 columns.  Functions from `tidyr` and `dplyr` are used to do the summary.

Finally, in step 7, the data and corresponding summary is written to the working directory in the form of two text files described in the CodeBook, and loaded into the memory as a list of two dataframes, as well.
 
